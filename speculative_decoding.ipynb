{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparation",
   "id": "f6de6af755fdb886"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:36.353241Z",
     "start_time": "2025-10-16T01:56:36.344046Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "# Download model\n",
    "huggingface-cli download tiiuae/Falcon3-1B-Instruct-1.58bit --local-dir ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit\n",
    "# Compile\n",
    "python setup_env.py -md ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit -q i2_s\n",
    "\n",
    "#.build/bin/llama-server -m /home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf --host 127.0.0.1 --port 8080\n",
    "\n",
    "# Download Falcon3-1B-Instruct\n",
    "huggingface-cli download tiiuae/Falcon3-1B-Instruct --local-dir ~/models/tiiuae/Falcon3-1B-Instruct\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Download model\\nhuggingface-cli download tiiuae/Falcon3-1B-Instruct-1.58bit --local-dir ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit\\n# Compile\\npython setup_env.py -md ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit -q i2_s\\n\\n#.build/bin/llama-server -m /home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf --host 127.0.0.1 --port 8080\\n\\n# Download Falcon3-1B-Instruct\\nhuggingface-cli download tiiuae/Falcon3-1B-Instruct --local-dir ~/models/tiiuae/Falcon3-1B-Instruct\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "dffe6bf4c285bea9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:38.647517Z",
     "start_time": "2025-10-16T01:56:36.357746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from utils import set_seed, BitNet"
   ],
   "id": "62ddb7478aa2932d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/miniconda3/envs/bitnet-cpp/lib/python3.9/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "f8e21d5ab2dcbde7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:37.995288Z",
     "start_time": "2025-10-16T01:56:37.991101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    # Debug\n",
    "    debug: bool = False\n",
    "    verbose: bool = True\n",
    "\n",
    "    # Model\n",
    "    model_id: str = \"tiiuae/Falcon3-1B-Instruct\"\n",
    "    model_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-f32.gguf\"\n",
    "    quantized_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf\"\n",
    "    ctx_size: int = 1024\n",
    "\n",
    "    # Generation\n",
    "    max_new_tokens: int = 256\n",
    "    ## Speculative Decoding\n",
    "    num_assistant_tokens: int = 5\n",
    "    assistant_confidence_threshold: float = 0.4\n",
    "\n",
    "    # Device\n",
    "    n_threads: int = 12\n",
    "\n",
    "    # Seed\n",
    "    seed = 42\n",
    "\n",
    "config = CONFIG()"
   ],
   "id": "a6b66f6771b15607",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:38.002170Z",
     "start_time": "2025-10-16T01:56:37.999342Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"",
   "id": "784cb1797748b6fc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:38.011713Z",
     "start_time": "2025-10-16T01:56:38.006926Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(config.seed)",
   "id": "ea880def9f4f766c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:38.072646Z",
     "start_time": "2025-10-16T01:56:38.069775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an helpful assistant.\"\n",
    "user_prompt = \"Explain quantum mechanics in detail please.\"\n",
    "assistant_response = \"Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons.\""
   ],
   "id": "16b44cddf2e377f0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "896a55c2e60df54a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T01:56:41.134855Z",
     "start_time": "2025-10-16T01:56:38.076913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet = BitNet(\n",
    "    model_id=config.model_id,\n",
    "    quantized_path=config.quantized_path,\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8080,\n",
    "    ctx_size=config.ctx_size,\n",
    "    n_threads=config.n_threads,\n",
    "    n_gpu_layers=0,\n",
    "    batch_size=1,\n",
    "    slot_id=1\n",
    ")\n",
    "bitnet.start_server(verbose=False)\n",
    "bitnet.init_tokenizer(verbose=False)\n",
    "bitnet.init_model(verbose=True)"
   ],
   "id": "ab56cfc0e8ed0735",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting llama-server on 127.0.0.1:8080\n",
      "✅ Server is ready.\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(131072, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=131072, bias=False)\n",
      ")\n",
      "Number of parameters: 1.67B\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-16T01:56:41.209383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet.speculative_decoding(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "    ),\n",
    "    max_new_tokens=100,\n",
    "    num_assistant_tokens=4,\n",
    "    confidence_threshold=0.25,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "76290b9214c56ec7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\u001B[0m\n",
      "✨ Starting Speculative Decoding\n",
      "├─ Target Model: tiiuae/Falcon3-1B-Instruct\n",
      "├─ Draft Model: /home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf\n",
      "└─ Draft Length: 4, Confidence: 0.2\n",
      "\u001B[95m──────────────────────────────────────────────────\u001B[0m\n",
      "\n",
      "\u001B[96m--- Step 1 ---\u001B[0m\n",
      "📝 \u001B[94mPrompting draft model with:\u001B[0m\n",
      "...quantum mechanics in detail please.\n",
      "<|assistant|>\n",
      "\n",
      "🚀 \u001B[93mDraft generated:\u001B[0m\n",
      "Sure, let' (4 tokens)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generation",
   "id": "469989eff49d9501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bitnet.generate_hf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    max_new_tokens=10,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "aaa8be819aa3e07a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bitnet.generate_gguf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    max_new_tokens=100,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "83a162b083561eb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speculative Decoding",
   "id": "b1edeead8fbf0100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bitnet.verify_hf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    num_verify=10,\n",
    "    confidence_threshold=0.4,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "c47fca931ad88e9b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
