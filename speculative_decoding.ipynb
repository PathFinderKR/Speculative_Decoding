{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparation",
   "id": "f6de6af755fdb886"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "# Download model\n",
    "huggingface-cli download tiiuae/Falcon3-3B-Instruct-1.58bit --local-dir ~/models/tiiuae/Falcon3-3B-Instruct-1.58bit\n",
    "# Compile\n",
    "python setup_env.py -md ~/models/tiiuae/Falcon3-3B-Instruct-1.58bit -q i2_s\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "dffe6bf4c285bea9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from utils import set_seed\n",
    "from speculative_decoding import BitNet"
   ],
   "id": "62ddb7478aa2932d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "f8e21d5ab2dcbde7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    # Debug\n",
    "    debug: bool = False\n",
    "    verbose: bool = True\n",
    "\n",
    "    # Model\n",
    "    ## Tokenizer\n",
    "    tokenizer_id: str = \"tiiuae/Falcon3-1B-Instruct\"\n",
    "    ## HuggingFace\n",
    "    model_path: str       = \"/home/pathfinder/models/tiiuae/Falcon3-3B-Instruct\"  # 3B\n",
    "    model_small_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct\"  # 1B\n",
    "    ## GGUF (1bit)\n",
    "    bitnet_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-3B-Instruct-1.58bit/ggml-model-i2_s.gguf\" # 3B\n",
    "    ctx_size: int = 1024\n",
    "\n",
    "    # Generation\n",
    "    max_new_tokens: int = 100\n",
    "    ## Speculative Decoding\n",
    "    num_assistant_tokens: int = 5\n",
    "    confidence_threshold: float = 0.4\n",
    "\n",
    "    # Device\n",
    "    n_threads: int = 12\n",
    "\n",
    "    # Seed\n",
    "    seed = 42\n",
    "\n",
    "config = CONFIG()"
   ],
   "id": "a6b66f6771b15607",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"",
   "id": "784cb1797748b6fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set_seed(config.seed)",
   "id": "ea880def9f4f766c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an helpful assistant.\"\n",
    "user_prompt = \"\tGiven a rational number, write it as a fraction in lowest terms and calculate the product of the resulting numerator and denominator. For how many rational numbers between 0 and 1 will $20_{}^{}!$ be the resulting product?\"\n",
    "assistant_response = \"The problem asks for the number of rational numbers between 0 and 1 such that when the rational number is written as a fraction in lowest terms, the product of the numerator and the denominator is $20!$.\""
   ],
   "id": "16b44cddf2e377f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "896a55c2e60df54a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bitnet = BitNet()\n",
    "bitnet.start_server(\n",
    "    bitnet_path=config.bitnet_path,\n",
    "    ctx_size=config.ctx_size,\n",
    "    n_threads=config.n_threads,\n",
    "    verbose=config.verbose\n",
    ")\n",
    "bitnet.init_tokenizer(\n",
    "    tokenizer_id=config.tokenizer_id,\n",
    "    verbose=False\n",
    ")\n",
    "bitnet.init_model(\n",
    "    model_path=config.model_path,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "ab56cfc0e8ed0735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text = bitnet.format_falcon_prompt(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    #assistant_response=assistant_response\n",
    ")\n",
    "print(text)"
   ],
   "id": "79f4caf365af7b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generation",
   "id": "fc1743343ce090f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3B (1bit)\n",
    "bitnet.generate_gguf(\n",
    "    text=text,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    verbose=config.verbose\n",
    ")"
   ],
   "id": "9411d6dc30b4635e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3B (fp32)\n",
    "bitnet.generate_hf(\n",
    "    text=text,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    stream=True,\n",
    "    verbose=config.verbose\n",
    ")"
   ],
   "id": "881141997c591c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "e7d0d41ac0096ba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speculative Decoding",
   "id": "4ef703cf32300f81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 32bit-1bit\n",
    "bitnet.speculative_decoding(\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    num_assistant_tokens=config.num_assistant_tokens,\n",
    "    confidence_threshold=config.confidence_threshold,\n",
    "    verbose=True\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "bea0e06e7bb1dc26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3B-1B\n",
    "bitnet.speculative_decoding_hf(\n",
    "    small_model=AutoModelForCausalLM.from_pretrained(\n",
    "        config.model_small_path,\n",
    "        device_map=\"cpu\",\n",
    "        dtype=torch.float32\n",
    "    ),\n",
    "    prompt=text,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    num_assistant_tokens=config.num_assistant_tokens,\n",
    "    confidence_threshold=config.confidence_threshold,\n",
    "    verbose=True\n",
    ")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "59ea59512c59f487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# 32bit-2bit",
   "id": "ba9928f877fa7140",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "86dd225e091894af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=/home/pathfinder/models/tiiuae/Falcon3-3B-Instruct,trust_remote_code=True \\\n",
    "    --tasks mmlu,hellaswag,gsm8k_cot,arc_easy \\\n",
    "    --num_fewshot 5 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 4 \\\n",
    "    --seed 1234 \\\n",
    "    --apply_chat_template \\\n",
    "    --output_path results \\\n",
    "    --log_samples \\\n",
    "    --wandb_args project=lm-eval-harness-integration\n",
    "\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct,trust_remote_code=True \\\n",
    "    --tasks mmlu,hellaswag,gsm8k_cot,arc_easy \\\n",
    "    --num_fewshot 5 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 4 \\\n",
    "    --seed 1234 \\\n",
    "    --apply_chat_template \\\n",
    "    --output_path results \\\n",
    "    --log_samples \\\n",
    "    --wandb_args project=lm-eval-harness-integration\n",
    "\n",
    "lm_eval --model hf \\\n",
    "    --model_args pretrained=tiiuae/Falcon3-3B-Instruct-1.58bit,trust_remote_code=True \\\n",
    "    --tasks mmlu,hellaswag,gsm8k_cot,arc_easy \\\n",
    "    --num_fewshot 5 \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 4 \\\n",
    "    --seed 1234 \\\n",
    "    --apply_chat_template \\\n",
    "    --output_path results \\\n",
    "    --log_samples \\\n",
    "    --wandb_args project=lm-eval-harness-integration\n",
    "\"\"\""
   ],
   "id": "ace6d8a6340333d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "hf (pretrained=/home/pathfinder/models/tiiuae/Falcon3-3B-Instruct,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 4\n",
    "|                 Tasks                 |Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
    "|---------------------------------------|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
    "|arc_easy                               |      1|none            |     5|acc        |↑  |0.7639|±  |0.0087|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.7719|±  |0.0086|\n",
    "|gsm8k_cot                              |      3|flexible-extract|     5|exact_match|↑  |0.7013|±  |0.0126|\n",
    "|                                       |       |strict-match    |     5|exact_match|↑  |0.7005|±  |0.0126|\n",
    "|hellaswag                              |      1|none            |     5|acc        |↑  |0.5227|±  |0.0050|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.6846|±  |0.0046|\n",
    "|mmlu                                   |      2|none            |      |acc        |↑  |0.5631|±  |0.0040|\n",
    "| - humanities                          |      2|none            |      |acc        |↑  |0.4869|±  |0.0068|\n",
    "|  - formal_logic                       |      1|none            |     5|acc        |↑  |0.4524|±  |0.0445|\n",
    "|  - high_school_european_history       |      1|none            |     5|acc        |↑  |0.6606|±  |0.0370|\n",
    "|  - high_school_us_history             |      1|none            |     5|acc        |↑  |0.7157|±  |0.0317|\n",
    "|  - high_school_world_history          |      1|none            |     5|acc        |↑  |0.7300|±  |0.0289|\n",
    "|  - international_law                  |      1|none            |     5|acc        |↑  |0.7190|±  |0.0410|\n",
    "|  - jurisprudence                      |      1|none            |     5|acc        |↑  |0.7037|±  |0.0441|\n",
    "|  - logical_fallacies                  |      1|none            |     5|acc        |↑  |0.7239|±  |0.0351|\n",
    "|  - moral_disputes                     |      1|none            |     5|acc        |↑  |0.6416|±  |0.0258|\n",
    "|  - moral_scenarios                    |      1|none            |     5|acc        |↑  |0.2235|±  |0.0139|\n",
    "|  - philosophy                         |      1|none            |     5|acc        |↑  |0.6463|±  |0.0272|\n",
    "|  - prehistory                         |      1|none            |     5|acc        |↑  |0.6049|±  |0.0272|\n",
    "|  - professional_law                   |      1|none            |     5|acc        |↑  |0.3748|±  |0.0124|\n",
    "|  - world_religions                    |      1|none            |     5|acc        |↑  |0.7661|±  |0.0325|\n",
    "| - other                               |      2|none            |      |acc        |↑  |0.6154|±  |0.0086|\n",
    "|  - business_ethics                    |      1|none            |     5|acc        |↑  |0.5700|±  |0.0498|\n",
    "|  - clinical_knowledge                 |      1|none            |     5|acc        |↑  |0.5962|±  |0.0302|\n",
    "|  - college_medicine                   |      1|none            |     5|acc        |↑  |0.5954|±  |0.0374|\n",
    "|  - global_facts                       |      1|none            |     5|acc        |↑  |0.3700|±  |0.0485|\n",
    "|  - human_aging                        |      1|none            |     5|acc        |↑  |0.6457|±  |0.0321|\n",
    "|  - management                         |      1|none            |     5|acc        |↑  |0.6990|±  |0.0454|\n",
    "|  - marketing                          |      1|none            |     5|acc        |↑  |0.7821|±  |0.0270|\n",
    "|  - medical_genetics                   |      1|none            |     5|acc        |↑  |0.6500|±  |0.0479|\n",
    "|  - miscellaneous                      |      1|none            |     5|acc        |↑  |0.7011|±  |0.0164|\n",
    "|  - nutrition                          |      1|none            |     5|acc        |↑  |0.6111|±  |0.0279|\n",
    "|  - professional_accounting            |      1|none            |     5|acc        |↑  |0.4681|±  |0.0298|\n",
    "|  - professional_medicine              |      1|none            |     5|acc        |↑  |0.5257|±  |0.0303|\n",
    "|  - virology                           |      1|none            |     5|acc        |↑  |0.4940|±  |0.0389|\n",
    "| - social sciences                     |      2|none            |      |acc        |↑  |0.6422|±  |0.0085|\n",
    "|  - econometrics                       |      1|none            |     5|acc        |↑  |0.5088|±  |0.0470|\n",
    "|  - high_school_geography              |      1|none            |     5|acc        |↑  |0.6869|±  |0.0330|\n",
    "|  - high_school_government_and_politics|      1|none            |     5|acc        |↑  |0.6736|±  |0.0338|\n",
    "|  - high_school_macroeconomics         |      1|none            |     5|acc        |↑  |0.5513|±  |0.0252|\n",
    "|  - high_school_microeconomics         |      1|none            |     5|acc        |↑  |0.6681|±  |0.0306|\n",
    "|  - high_school_psychology             |      1|none            |     5|acc        |↑  |0.7468|±  |0.0186|\n",
    "|  - human_sexuality                    |      1|none            |     5|acc        |↑  |0.6183|±  |0.0426|\n",
    "|  - professional_psychology            |      1|none            |     5|acc        |↑  |0.5441|±  |0.0201|\n",
    "|  - public_relations                   |      1|none            |     5|acc        |↑  |0.5818|±  |0.0472|\n",
    "|  - security_studies                   |      1|none            |     5|acc        |↑  |0.6980|±  |0.0294|\n",
    "|  - sociology                          |      1|none            |     5|acc        |↑  |0.7413|±  |0.0310|\n",
    "|  - us_foreign_policy                  |      1|none            |     5|acc        |↑  |0.7300|±  |0.0446|\n",
    "| - stem                                |      2|none            |      |acc        |↑  |0.5480|±  |0.0086|\n",
    "|  - abstract_algebra                   |      1|none            |     5|acc        |↑  |0.3000|±  |0.0461|\n",
    "|  - anatomy                            |      1|none            |     5|acc        |↑  |0.5333|±  |0.0431|\n",
    "|  - astronomy                          |      1|none            |     5|acc        |↑  |0.6908|±  |0.0376|\n",
    "|  - college_biology                    |      1|none            |     5|acc        |↑  |0.7222|±  |0.0375|\n",
    "|  - college_chemistry                  |      1|none            |     5|acc        |↑  |0.5500|±  |0.0500|\n",
    "|  - college_computer_science           |      1|none            |     5|acc        |↑  |0.5200|±  |0.0502|\n",
    "|  - college_mathematics                |      1|none            |     5|acc        |↑  |0.3800|±  |0.0488|\n",
    "|  - college_physics                    |      1|none            |     5|acc        |↑  |0.4412|±  |0.0494|\n",
    "|  - computer_security                  |      1|none            |     5|acc        |↑  |0.7500|±  |0.0435|\n",
    "|  - conceptual_physics                 |      1|none            |     5|acc        |↑  |0.6340|±  |0.0315|\n",
    "|  - electrical_engineering             |      1|none            |     5|acc        |↑  |0.6345|±  |0.0401|\n",
    "|  - elementary_mathematics             |      1|none            |     5|acc        |↑  |0.4815|±  |0.0257|\n",
    "|  - high_school_biology                |      1|none            |     5|acc        |↑  |0.6968|±  |0.0261|\n",
    "|  - high_school_chemistry              |      1|none            |     5|acc        |↑  |0.5665|±  |0.0349|\n",
    "|  - high_school_computer_science       |      1|none            |     5|acc        |↑  |0.6700|±  |0.0473|\n",
    "|  - high_school_mathematics            |      1|none            |     5|acc        |↑  |0.3704|±  |0.0294|\n",
    "|  - high_school_physics                |      1|none            |     5|acc        |↑  |0.4636|±  |0.0407|\n",
    "|  - high_school_statistics             |      1|none            |     5|acc        |↑  |0.5139|±  |0.0341|\n",
    "|  - machine_learning                   |      1|none            |     5|acc        |↑  |0.4464|±  |0.0472|\n",
    "\n",
    "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
    "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
    "|mmlu              |      2|none  |      |acc   |↑  |0.5631|±  |0.0040|\n",
    "| - humanities     |      2|none  |      |acc   |↑  |0.4869|±  |0.0068|\n",
    "| - other          |      2|none  |      |acc   |↑  |0.6154|±  |0.0086|\n",
    "| - social sciences|      2|none  |      |acc   |↑  |0.6422|±  |0.0085|\n",
    "| - stem           |      2|none  |      |acc   |↑  |0.5480|±  |0.0086|\n",
    "\"\"\""
   ],
   "id": "864f4572c0d97e29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "hf (pretrained=/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 4\n",
    "|                 Tasks                 |Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
    "|---------------------------------------|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
    "|arc_easy                               |      1|none            |     5|acc        |↑  |0.7378|±  |0.0090|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.7285|±  |0.0091|\n",
    "|gsm8k_cot                              |      3|flexible-extract|     5|exact_match|↑  |0.4071|±  |0.0135|\n",
    "|                                       |       |strict-match    |     5|exact_match|↑  |0.4026|±  |0.0135|\n",
    "|hellaswag                              |      1|none            |     5|acc        |↑  |0.4648|±  |0.0050|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.6009|±  |0.0049|\n",
    "|mmlu                                   |      2|none            |      |acc        |↑  |0.4474|±  |0.0041|\n",
    "| - humanities                          |      2|none            |      |acc        |↑  |0.4049|±  |0.0069|\n",
    "|  - formal_logic                       |      1|none            |     5|acc        |↑  |0.3333|±  |0.0422|\n",
    "|  - high_school_european_history       |      1|none            |     5|acc        |↑  |0.6000|±  |0.0383|\n",
    "|  - high_school_us_history             |      1|none            |     5|acc        |↑  |0.5588|±  |0.0348|\n",
    "|  - high_school_world_history          |      1|none            |     5|acc        |↑  |0.6160|±  |0.0317|\n",
    "|  - international_law                  |      1|none            |     5|acc        |↑  |0.5537|±  |0.0454|\n",
    "|  - jurisprudence                      |      1|none            |     5|acc        |↑  |0.4630|±  |0.0482|\n",
    "|  - logical_fallacies                  |      1|none            |     5|acc        |↑  |0.4847|±  |0.0393|\n",
    "|  - moral_disputes                     |      1|none            |     5|acc        |↑  |0.5231|±  |0.0269|\n",
    "|  - moral_scenarios                    |      1|none            |     5|acc        |↑  |0.2346|±  |0.0142|\n",
    "|  - philosophy                         |      1|none            |     5|acc        |↑  |0.4502|±  |0.0283|\n",
    "|  - prehistory                         |      1|none            |     5|acc        |↑  |0.5031|±  |0.0278|\n",
    "|  - professional_law                   |      1|none            |     5|acc        |↑  |0.3357|±  |0.0121|\n",
    "|  - world_religions                    |      1|none            |     5|acc        |↑  |0.5789|±  |0.0379|\n",
    "| - other                               |      2|none            |      |acc        |↑  |0.4976|±  |0.0087|\n",
    "|  - business_ethics                    |      1|none            |     5|acc        |↑  |0.5000|±  |0.0503|\n",
    "|  - clinical_knowledge                 |      1|none            |     5|acc        |↑  |0.5396|±  |0.0307|\n",
    "|  - college_medicine                   |      1|none            |     5|acc        |↑  |0.4277|±  |0.0377|\n",
    "|  - global_facts                       |      1|none            |     5|acc        |↑  |0.2600|±  |0.0441|\n",
    "|  - human_aging                        |      1|none            |     5|acc        |↑  |0.4574|±  |0.0334|\n",
    "|  - management                         |      1|none            |     5|acc        |↑  |0.6602|±  |0.0469|\n",
    "|  - marketing                          |      1|none            |     5|acc        |↑  |0.7009|±  |0.0300|\n",
    "|  - medical_genetics                   |      1|none            |     5|acc        |↑  |0.5100|±  |0.0502|\n",
    "|  - miscellaneous                      |      1|none            |     5|acc        |↑  |0.5785|±  |0.0177|\n",
    "|  - nutrition                          |      1|none            |     5|acc        |↑  |0.5261|±  |0.0286|\n",
    "|  - professional_accounting            |      1|none            |     5|acc        |↑  |0.3475|±  |0.0284|\n",
    "|  - professional_medicine              |      1|none            |     5|acc        |↑  |0.3162|±  |0.0282|\n",
    "|  - virology                           |      1|none            |     5|acc        |↑  |0.4217|±  |0.0384|\n",
    "| - social sciences                     |      2|none            |      |acc        |↑  |0.5180|±  |0.0088|\n",
    "|  - econometrics                       |      1|none            |     5|acc        |↑  |0.3246|±  |0.0440|\n",
    "|  - high_school_geography              |      1|none            |     5|acc        |↑  |0.5960|±  |0.0350|\n",
    "|  - high_school_government_and_politics|      1|none            |     5|acc        |↑  |0.5959|±  |0.0354|\n",
    "|  - high_school_macroeconomics         |      1|none            |     5|acc        |↑  |0.4154|±  |0.0250|\n",
    "|  - high_school_microeconomics         |      1|none            |     5|acc        |↑  |0.4790|±  |0.0324|\n",
    "|  - high_school_psychology             |      1|none            |     5|acc        |↑  |0.6239|±  |0.0208|\n",
    "|  - human_sexuality                    |      1|none            |     5|acc        |↑  |0.5191|±  |0.0438|\n",
    "|  - professional_psychology            |      1|none            |     5|acc        |↑  |0.4020|±  |0.0198|\n",
    "|  - public_relations                   |      1|none            |     5|acc        |↑  |0.5909|±  |0.0471|\n",
    "|  - security_studies                   |      1|none            |     5|acc        |↑  |0.5510|±  |0.0318|\n",
    "|  - sociology                          |      1|none            |     5|acc        |↑  |0.6368|±  |0.0340|\n",
    "|  - us_foreign_policy                  |      1|none            |     5|acc        |↑  |0.6600|±  |0.0476|\n",
    "| - stem                                |      2|none            |      |acc        |↑  |0.3923|±  |0.0086|\n",
    "|  - abstract_algebra                   |      1|none            |     5|acc        |↑  |0.2200|±  |0.0416|\n",
    "|  - anatomy                            |      1|none            |     5|acc        |↑  |0.4296|±  |0.0428|\n",
    "|  - astronomy                          |      1|none            |     5|acc        |↑  |0.4868|±  |0.0407|\n",
    "|  - college_biology                    |      1|none            |     5|acc        |↑  |0.4167|±  |0.0412|\n",
    "|  - college_chemistry                  |      1|none            |     5|acc        |↑  |0.3500|±  |0.0479|\n",
    "|  - college_computer_science           |      1|none            |     5|acc        |↑  |0.4500|±  |0.0500|\n",
    "|  - college_mathematics                |      1|none            |     5|acc        |↑  |0.3300|±  |0.0473|\n",
    "|  - college_physics                    |      1|none            |     5|acc        |↑  |0.3137|±  |0.0462|\n",
    "|  - computer_security                  |      1|none            |     5|acc        |↑  |0.5700|±  |0.0498|\n",
    "|  - conceptual_physics                 |      1|none            |     5|acc        |↑  |0.4043|±  |0.0321|\n",
    "|  - electrical_engineering             |      1|none            |     5|acc        |↑  |0.4966|±  |0.0417|\n",
    "|  - elementary_mathematics             |      1|none            |     5|acc        |↑  |0.3122|±  |0.0239|\n",
    "|  - high_school_biology                |      1|none            |     5|acc        |↑  |0.5516|±  |0.0283|\n",
    "|  - high_school_chemistry              |      1|none            |     5|acc        |↑  |0.3793|±  |0.0341|\n",
    "|  - high_school_computer_science       |      1|none            |     5|acc        |↑  |0.4800|±  |0.0502|\n",
    "|  - high_school_mathematics            |      1|none            |     5|acc        |↑  |0.2741|±  |0.0272|\n",
    "|  - high_school_physics                |      1|none            |     5|acc        |↑  |0.2649|±  |0.0360|\n",
    "|  - high_school_statistics             |      1|none            |     5|acc        |↑  |0.3843|±  |0.0332|\n",
    "|  - machine_learning                   |      1|none            |     5|acc        |↑  |0.3839|±  |0.0462|\n",
    "\n",
    "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
    "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
    "|mmlu              |      2|none  |      |acc   |↑  |0.4474|±  |0.0041|\n",
    "| - humanities     |      2|none  |      |acc   |↑  |0.4049|±  |0.0069|\n",
    "| - other          |      2|none  |      |acc   |↑  |0.4976|±  |0.0087|\n",
    "| - social sciences|      2|none  |      |acc   |↑  |0.5180|±  |0.0088|\n",
    "| - stem           |      2|none  |      |acc   |↑  |0.3923|±  |0.0086|\n",
    "\"\"\""
   ],
   "id": "f2a46cc352769976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "hf (pretrained=tiiuae/Falcon3-3B-Instruct-1.58bit,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 4\n",
    "|                 Tasks                 |Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
    "|---------------------------------------|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
    "|arc_easy                               |      1|none            |     5|acc        |↑  |0.5741|±  |0.0101|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.5303|±  |0.0102|\n",
    "|gsm8k_cot                              |      3|flexible-extract|     5|exact_match|↑  |0.0591|±  |0.0065|\n",
    "|                                       |       |strict-match    |     5|exact_match|↑  |0.3427|±  |0.0131|\n",
    "|hellaswag                              |      1|none            |     5|acc        |↑  |0.3919|±  |0.0049|\n",
    "|                                       |       |none            |     5|acc_norm   |↑  |0.5008|±  |0.0050|\n",
    "|mmlu                                   |      2|none            |      |acc        |↑  |0.2425|±  |0.0036|\n",
    "| - humanities                          |      2|none            |      |acc        |↑  |0.2465|±  |0.0063|\n",
    "|  - formal_logic                       |      1|none            |     5|acc        |↑  |0.2857|±  |0.0404|\n",
    "|  - high_school_european_history       |      1|none            |     5|acc        |↑  |0.2121|±  |0.0319|\n",
    "|  - high_school_us_history             |      1|none            |     5|acc        |↑  |0.2402|±  |0.0300|\n",
    "|  - high_school_world_history          |      1|none            |     5|acc        |↑  |0.2616|±  |0.0286|\n",
    "|  - international_law                  |      1|none            |     5|acc        |↑  |0.2397|±  |0.0390|\n",
    "|  - jurisprudence                      |      1|none            |     5|acc        |↑  |0.2870|±  |0.0437|\n",
    "|  - logical_fallacies                  |      1|none            |     5|acc        |↑  |0.2025|±  |0.0316|\n",
    "|  - moral_disputes                     |      1|none            |     5|acc        |↑  |0.2312|±  |0.0227|\n",
    "|  - moral_scenarios                    |      1|none            |     5|acc        |↑  |0.2469|±  |0.0144|\n",
    "|  - philosophy                         |      1|none            |     5|acc        |↑  |0.2315|±  |0.0240|\n",
    "|  - prehistory                         |      1|none            |     5|acc        |↑  |0.2284|±  |0.0234|\n",
    "|  - professional_law                   |      1|none            |     5|acc        |↑  |0.2477|±  |0.0110|\n",
    "|  - world_religions                    |      1|none            |     5|acc        |↑  |0.3392|±  |0.0363|\n",
    "| - other                               |      2|none            |      |acc        |↑  |0.2646|±  |0.0079|\n",
    "|  - business_ethics                    |      1|none            |     5|acc        |↑  |0.3100|±  |0.0465|\n",
    "|  - clinical_knowledge                 |      1|none            |     5|acc        |↑  |0.2151|±  |0.0253|\n",
    "|  - college_medicine                   |      1|none            |     5|acc        |↑  |0.2370|±  |0.0324|\n",
    "|  - global_facts                       |      1|none            |     5|acc        |↑  |0.1800|±  |0.0386|\n",
    "|  - human_aging                        |      1|none            |     5|acc        |↑  |0.3274|±  |0.0315|\n",
    "|  - management                         |      1|none            |     5|acc        |↑  |0.2039|±  |0.0399|\n",
    "|  - marketing                          |      1|none            |     5|acc        |↑  |0.3120|±  |0.0304|\n",
    "|  - medical_genetics                   |      1|none            |     5|acc        |↑  |0.3200|±  |0.0469|\n",
    "|  - miscellaneous                      |      1|none            |     5|acc        |↑  |0.3116|±  |0.0166|\n",
    "|  - nutrition                          |      1|none            |     5|acc        |↑  |0.2353|±  |0.0243|\n",
    "|  - professional_accounting            |      1|none            |     5|acc        |↑  |0.2234|±  |0.0248|\n",
    "|  - professional_medicine              |      1|none            |     5|acc        |↑  |0.1838|±  |0.0235|\n",
    "|  - virology                           |      1|none            |     5|acc        |↑  |0.2831|±  |0.0351|\n",
    "| - social sciences                     |      2|none            |      |acc        |↑  |0.2424|±  |0.0077|\n",
    "|  - econometrics                       |      1|none            |     5|acc        |↑  |0.2368|±  |0.0400|\n",
    "|  - high_school_geography              |      1|none            |     5|acc        |↑  |0.2172|±  |0.0294|\n",
    "|  - high_school_government_and_politics|      1|none            |     5|acc        |↑  |0.2124|±  |0.0295|\n",
    "|  - high_school_macroeconomics         |      1|none            |     5|acc        |↑  |0.2256|±  |0.0212|\n",
    "|  - high_school_microeconomics         |      1|none            |     5|acc        |↑  |0.2227|±  |0.0270|\n",
    "|  - high_school_psychology             |      1|none            |     5|acc        |↑  |0.2128|±  |0.0175|\n",
    "|  - human_sexuality                    |      1|none            |     5|acc        |↑  |0.2748|±  |0.0392|\n",
    "|  - professional_psychology            |      1|none            |     5|acc        |↑  |0.3056|±  |0.0186|\n",
    "|  - public_relations                   |      1|none            |     5|acc        |↑  |0.2727|±  |0.0427|\n",
    "|  - security_studies                   |      1|none            |     5|acc        |↑  |0.1837|±  |0.0248|\n",
    "|  - sociology                          |      1|none            |     5|acc        |↑  |0.2537|±  |0.0308|\n",
    "|  - us_foreign_policy                  |      1|none            |     5|acc        |↑  |0.2900|±  |0.0456|\n",
    "| - stem                                |      2|none            |      |acc        |↑  |0.2147|±  |0.0073|\n",
    "|  - abstract_algebra                   |      1|none            |     5|acc        |↑  |0.2200|±  |0.0416|\n",
    "|  - anatomy                            |      1|none            |     5|acc        |↑  |0.1778|±  |0.0330|\n",
    "|  - astronomy                          |      1|none            |     5|acc        |↑  |0.1908|±  |0.0320|\n",
    "|  - college_biology                    |      1|none            |     5|acc        |↑  |0.2222|±  |0.0348|\n",
    "|  - college_chemistry                  |      1|none            |     5|acc        |↑  |0.2000|±  |0.0402|\n",
    "|  - college_computer_science           |      1|none            |     5|acc        |↑  |0.2600|±  |0.0441|\n",
    "|  - college_mathematics                |      1|none            |     5|acc        |↑  |0.2100|±  |0.0409|\n",
    "|  - college_physics                    |      1|none            |     5|acc        |↑  |0.2157|±  |0.0409|\n",
    "|  - computer_security                  |      1|none            |     5|acc        |↑  |0.2600|±  |0.0441|\n",
    "|  - conceptual_physics                 |      1|none            |     5|acc        |↑  |0.2809|±  |0.0294|\n",
    "|  - electrical_engineering             |      1|none            |     5|acc        |↑  |0.2414|±  |0.0357|\n",
    "|  - elementary_mathematics             |      1|none            |     5|acc        |↑  |0.2090|±  |0.0209|\n",
    "|  - high_school_biology                |      1|none            |     5|acc        |↑  |0.1903|±  |0.0223|\n",
    "|  - high_school_chemistry              |      1|none            |     5|acc        |↑  |0.1626|±  |0.0260|\n",
    "|  - high_school_computer_science       |      1|none            |     5|acc        |↑  |0.2700|±  |0.0446|\n",
    "|  - high_school_mathematics            |      1|none            |     5|acc        |↑  |0.2111|±  |0.0249|\n",
    "|  - high_school_physics                |      1|none            |     5|acc        |↑  |0.1987|±  |0.0326|\n",
    "|  - high_school_statistics             |      1|none            |     5|acc        |↑  |0.1574|±  |0.0248|\n",
    "|  - machine_learning                   |      1|none            |     5|acc        |↑  |0.3125|±  |0.0440|\n",
    "\n",
    "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
    "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
    "|mmlu              |      2|none  |      |acc   |↑  |0.2425|±  |0.0036|\n",
    "| - humanities     |      2|none  |      |acc   |↑  |0.2465|±  |0.0063|\n",
    "| - other          |      2|none  |      |acc   |↑  |0.2646|±  |0.0079|\n",
    "| - social sciences|      2|none  |      |acc   |↑  |0.2424|±  |0.0077|\n",
    "| - stem           |      2|none  |      |acc   |↑  |0.2147|±  |0.0073|\n",
    "\"\"\""
   ],
   "id": "22d9fb037cbc2f74",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
