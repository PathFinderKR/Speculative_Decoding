{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparation",
   "id": "f6de6af755fdb886"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:22.913711Z",
     "start_time": "2025-10-15T17:40:22.905053Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "# Download model\n",
    "huggingface-cli download tiiuae/Falcon3-1B-Instruct-1.58bit --local-dir ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit\n",
    "# Compile\n",
    "python setup_env.py -md ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit -q i2_s\n",
    "\n",
    "#.build/bin/llama-server -m /home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf --host 127.0.0.1 --port 8080\n",
    "\n",
    "# Download Falcon3-1B-Instruct\n",
    "huggingface-cli download tiiuae/Falcon3-1B-Instruct --local-dir ~/models/tiiuae/Falcon3-1B-Instruct\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Download model\\nhuggingface-cli download tiiuae/Falcon3-1B-Instruct-1.58bit --local-dir ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit\\n# Compile\\npython setup_env.py -md ~/models/tiiuae/Falcon3-1B-Instruct-1.58bit -q i2_s\\n\\n#.build/bin/llama-server -m /home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf --host 127.0.0.1 --port 8080\\n\\n# Download Falcon3-1B-Instruct\\nhuggingface-cli download tiiuae/Falcon3-1B-Instruct --local-dir ~/models/tiiuae/Falcon3-1B-Instruct\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "dffe6bf4c285bea9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:25.344816Z",
     "start_time": "2025-10-15T17:40:22.926859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from utils import set_seed, BitNet\n",
    "#from speculative_decoding import generate_draft_response, speculative_decoding, verify_with_target"
   ],
   "id": "62ddb7478aa2932d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathfinder/miniconda3/envs/bitnet-cpp/lib/python3.9/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "f8e21d5ab2dcbde7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:25.385360Z",
     "start_time": "2025-10-15T17:40:25.381294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CONFIG:\n",
    "    # Debug\n",
    "    debug: bool = False\n",
    "    verbose: bool = True\n",
    "\n",
    "    # Model\n",
    "    model_id: str = \"tiiuae/Falcon3-1B-Instruct\"\n",
    "    model_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-f32.gguf\"\n",
    "    quantized_path: str = \"/home/pathfinder/models/tiiuae/Falcon3-1B-Instruct-1.58bit/ggml-model-i2_s.gguf\"\n",
    "    ctx_size: int = 1024\n",
    "\n",
    "    # Generation\n",
    "    max_new_tokens: int = 256\n",
    "    ## Speculative Decoding\n",
    "    num_assistant_tokens: int = 5\n",
    "    assistant_confidence_threshold: float = 0.4\n",
    "\n",
    "    # Device\n",
    "    n_threads: int = 12\n",
    "\n",
    "    # Seed\n",
    "    seed = 42\n",
    "\n",
    "config = CONFIG()"
   ],
   "id": "a6b66f6771b15607",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:25.393719Z",
     "start_time": "2025-10-15T17:40:25.389398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = \"cpu\""
   ],
   "id": "784cb1797748b6fc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:25.402307Z",
     "start_time": "2025-10-15T17:40:25.398212Z"
    }
   },
   "cell_type": "code",
   "source": "set_seed(config.seed)",
   "id": "ea880def9f4f766c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:25.413670Z",
     "start_time": "2025-10-15T17:40:25.410631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are an helpful assistant.\"\n",
    "user_prompt = \"Explain quantum mechanics in detail please.\"\n",
    "assistant_response = \"Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons.\""
   ],
   "id": "16b44cddf2e377f0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "896a55c2e60df54a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:31.633126Z",
     "start_time": "2025-10-15T17:40:25.418706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet = BitNet(\n",
    "    model_id=config.model_id,\n",
    "    quantized_path=config.quantized_path,\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8080,\n",
    "    ctx_size=config.ctx_size,\n",
    "    n_threads=config.n_threads,\n",
    "    n_gpu_layers=0,\n",
    "    batch_size=1,\n",
    "    slot_id=1\n",
    ")\n",
    "bitnet.start_server(verbose=False)\n",
    "bitnet.init_tokenizer(verbose=False)\n",
    "bitnet.init_model(verbose=True)"
   ],
   "id": "e7bafe8ecbfa69ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting llama-server on 127.0.0.1:8080\n",
      "✅ Server is ready.\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(131072, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=131072, bias=False)\n",
      ")\n",
      "Number of parameters: 1.67B\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generation",
   "id": "6463ae4e2d78bcab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:35.093976Z",
     "start_time": "2025-10-15T17:40:31.657534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet.generate_hf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    max_new_tokens=10,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "b658b8ab8e5c099b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are an helpful assistant.\n",
      "<|user|>\n",
      "Explain quantum mechanics in detail please.\n",
      "<|assistant|>\n",
      "Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons. It is a complex and counterintuitive theory that has been\n",
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\n",
      "🧠 Generation Info (Hugging Face)\n",
      "──────────────────────────────────────────────────\u001B[0m\n",
      "\u001B[94m💬 User Input:\u001B[0m\n",
      "<|system|>\n",
      "You are an helpful assistant.\n",
      "<|user|>\n",
      "Explain quantum mechanics in detail please.\n",
      "<|assistant|>\n",
      "Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons.\n",
      "\n",
      "\u001B[92m🟢 Generated Text:\u001B[0m\n",
      " It is a complex and counterintuitive theory that has been\n",
      "\n",
      "\u001B[94m📊 Timings:\u001B[0m\n",
      "  - Total Time: 3.41s\n",
      "  - Decode: 341.33 ms/token, 2.93 tokens/s\n",
      "\u001B[94m📦 Tokens:\u001B[0m\n",
      "  - Prefilled: 64\n",
      "  - Decoded: 10\n",
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\n",
      "💡 Token Probabilities\n",
      "──────────────────────────────────────────────────\u001B[0m\n",
      "| Step | Token           |  Probability |\n",
      "|------|-----------------|--------------|\n",
      "|    1 |  It             |       63.56% |\n",
      "|    2 |  is             |       25.70% |\n",
      "|    3 |  a              |       48.73% |\n",
      "|    4 |  complex        |       19.01% |\n",
      "|    5 |  and            |       48.46% |\n",
      "|    6 |  counterintuiti |       20.87% |\n",
      "|    7 |  theory         |       52.42% |\n",
      "|    8 |  that           |       50.88% |\n",
      "|    9 |  has            |       25.30% |\n",
      "|   10 |  been           |       44.32% |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' It is a complex and counterintuitive theory that has been'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:38.084450Z",
     "start_time": "2025-10-15T17:40:35.113161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet.generate_gguf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    max_new_tokens=100,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "83bc37427064dc39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\n",
      "🧠 Generation Info\n",
      "──────────────────────────────────────────────────\u001B[0m\n",
      "\u001B[94m💬 User Input:\u001B[0m\n",
      "<|system|>\n",
      "You are an helpful assistant.\n",
      "<|user|>\n",
      "Explain quantum mechanics in detail please.\n",
      "<|assistant|>\n",
      "Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons.\n",
      "\n",
      "\u001B[92m🟢 Generated Text:\u001B[0m\n",
      " At its core, quantum mechanics is based on the idea that not all electromagnetic fields can be described by classical mechanics through classical fields like electromagnetic tension and dipole moments. Instead, these fields are described by the concept of quantum fields, and these fields can be generated by pairs of entangled particles. The light color of the particle contributes to the field's quantum state, and the system’s qubit relies on superposition to maintain this quantum state over time to change states.\n",
      "\n",
      "\u001B[94m📊 Timings:\u001B[0m\n",
      "  - Prefill: 2.81 ms/token, 355.39 tokens/s\n",
      "  - Decode: 29.27 ms/token, 34.16 tokens/s\n",
      "\u001B[94m📦 Tokens:\u001B[0m\n",
      "  - Prefilled: 64\n",
      "  - Decoded: 95\n",
      "\u001B[94m🛑 Stop Reason:\u001B[0m EOS\n",
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\n",
      "💡 Token Probabilities\n",
      "──────────────────────────────────────────────────\u001B[0m\n",
      "| Step | Token           |  Probability |\u001B[0m\n",
      "|------|-----------------|--------------|\u001B[0m\n",
      "|    1 |  At             |       61.01% |\u001B[0m\n",
      "|    2 |  its            |       47.76% |\u001B[0m\n",
      "|    3 |  core           |       79.32% |\u001B[0m\n",
      "|    4 | ,               |       99.23% |\u001B[0m\n",
      "|    5 |  quantum        |       75.94% |\u001B[0m\n",
      "|    6 |  mechanics      |       99.58% |\u001B[0m\n",
      "|    7 |  is             |       54.14% |\u001B[0m\n",
      "|    8 |  based          |       53.95% |\u001B[0m\n",
      "|    9 |  on             |       99.46% |\u001B[0m\n",
      "|   10 |  the            |       83.20% |\u001B[0m\n",
      "|   11 |  idea           |       34.69% |\u001B[0m\n",
      "|   12 |  that           |       94.93% |\u001B[0m\n",
      "|   13 |  not            |       21.65% |\u001B[0m\n",
      "|   14 |  all            |       58.40% |\u001B[0m\n",
      "|   15 |  electromagneti |       34.65% |\u001B[0m\n",
      "|   16 |  fields         |       27.16% |\u001B[0m\n",
      "|   17 |  can            |       37.28% |\u001B[0m\n",
      "|   18 |  be             |       98.78% |\u001B[0m\n",
      "|   19 |  described      |       61.49% |\u001B[0m\n",
      "|   20 |  by             |       80.42% |\u001B[0m\n",
      "|   21 |  classical      |       67.32% |\u001B[0m\n",
      "|   22 |  mechanics      |       41.99% |\u001B[0m\n",
      "|   23 |  through        |       50.49% |\u001B[0m\n",
      "|   24 |  classical      |       20.34% |\u001B[0m\n",
      "|   25 |  fields         |       16.14% |\u001B[0m\n",
      "|   26 |  like           |       32.75% |\u001B[0m\n",
      "|   27 |  electromagneti |       10.84% |\u001B[0m\n",
      "|   28 |  tension        |       32.74% |\u001B[0m\n",
      "|   29 |  and            |       59.94% |\u001B[0m\n",
      "|   30 |  dipole         |       28.60% |\u001B[0m\n",
      "|   31 |  moments        |       41.68% |\u001B[0m\n",
      "|   32 | .               |       82.31% |\u001B[0m\n",
      "|   33 |  Instead        |       43.49% |\u001B[0m\n",
      "|   34 | ,               |       99.78% |\u001B[0m\n",
      "|   35 |  these          |       22.37% |\u001B[0m\n",
      "|   36 |  fields         |       77.77% |\u001B[0m\n",
      "|   37 |  are            |       35.07% |\u001B[0m\n",
      "|   38 |  described      |       57.22% |\u001B[0m\n",
      "|   39 |  by             |       83.59% |\u001B[0m\n",
      "|   40 |  the            |       62.80% |\u001B[0m\n",
      "|   41 |  concept        |       27.84% |\u001B[0m\n",
      "|   42 |  of             |       99.71% |\u001B[0m\n",
      "|   43 |  quantum        |       82.69% |\u001B[0m\n",
      "|   44 |  fields         |       88.26% |\u001B[0m\n",
      "|   45 | ,               |       46.13% |\u001B[0m\n",
      "|   46 |  and            |       65.84% |\u001B[0m\n",
      "|   47 |  these          |       24.57% |\u001B[0m\n",
      "|   48 |  fields         |       68.67% |\u001B[0m\n",
      "|   49 |  can            |       41.90% |\u001B[0m\n",
      "|   50 |  be             |       62.95% |\u001B[0m\n",
      "|   51 |  generated      |       40.41% |\u001B[0m\n",
      "|   52 |  by             |       59.29% |\u001B[0m\n",
      "|   53 |  pairs          |       17.09% |\u001B[0m\n",
      "|   54 |  of             |       97.87% |\u001B[0m\n",
      "|   55 |  entangled      |       19.80% |\u001B[0m\n",
      "|   56 |  particles      |       72.22% |\u001B[0m\n",
      "|   57 | .               |       68.75% |\u001B[0m\n",
      "|   58 |  The            |       43.33% |\u001B[0m\n",
      "|   59 |  light          |        7.70% |\u001B[0m\n",
      "|   60 |  color          |       21.85% |\u001B[0m\n",
      "|   61 |  of             |       78.72% |\u001B[0m\n",
      "|   62 |  the            |       42.51% |\u001B[0m\n",
      "|   63 |  particle       |       31.42% |\u001B[0m\n",
      "|   64 |  contributes    |       33.27% |\u001B[0m\n",
      "|   65 |  to             |       85.91% |\u001B[0m\n",
      "|   66 |  the            |       46.26% |\u001B[0m\n",
      "|   67 |  field          |       18.22% |\u001B[0m\n",
      "|   68 | '               |       29.34% |\u001B[0m\n",
      "|   69 | s               |       99.98% |\u001B[0m\n",
      "|   70 |  quantum        |       31.58% |\u001B[0m\n",
      "|   71 |  state          |       29.63% |\u001B[0m\n",
      "|   72 | ,               |       47.74% |\u001B[0m\n",
      "|   73 |  and            |       44.11% |\u001B[0m\n",
      "|   74 |  the            |       43.09% |\u001B[0m\n",
      "|   75 |  system         |       11.73% |\u001B[0m\n",
      "|   76 | ’               |       26.57% |\u001B[0m\n",
      "|   77 | s               |       99.94% |\u001B[0m\n",
      "|   78 |  qu             |       21.30% |\u001B[0m\n",
      "|   79 | bit             |       64.26% |\u001B[0m\n",
      "|   80 |  relies         |       19.07% |\u001B[0m\n",
      "|   81 |  on             |       96.49% |\u001B[0m\n",
      "|   82 |  super          |       24.07% |\u001B[0m\n",
      "|   83 | position        |       97.29% |\u001B[0m\n",
      "|   84 |  to             |       50.53% |\u001B[0m\n",
      "|   85 |  maintain       |       30.50% |\u001B[0m\n",
      "|   86 |  this           |       22.81% |\u001B[0m\n",
      "|   87 |  quantum        |       51.80% |\u001B[0m\n",
      "|   88 |  state          |       96.09% |\u001B[0m\n",
      "|   89 |  over           |       54.46% |\u001B[0m\n",
      "|   90 |  time           |       75.71% |\u001B[0m\n",
      "|   91 |  to             |       82.97% |\u001B[0m\n",
      "|   92 |  change         |       19.54% |\u001B[0m\n",
      "|   93 |  states         |       51.57% |\u001B[0m\n",
      "|   94 | .               |       50.17% |\u001B[0m\n",
      "|   95 | <|endoftext|>   |       30.46% |\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" At its core, quantum mechanics is based on the idea that not all electromagnetic fields can be described by classical mechanics through classical fields like electromagnetic tension and dipole moments. Instead, these fields are described by the concept of quantum fields, and these fields can be generated by pairs of entangled particles. The light color of the particle contributes to the field's quantum state, and the system’s qubit relies on superposition to maintain this quantum state over time to change states.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speculative Decoding",
   "id": "3ea2f613adff62cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:41:09.045256Z",
     "start_time": "2025-10-15T17:41:08.284931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bitnet.verify_hf(\n",
    "    text=bitnet.format_falcon_prompt(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ),\n",
    "    num_verify=10,\n",
    "    confidence_threshold=0.4,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "a486eb7c42cc989c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[95m──────────────────────────────────────────────────\n",
      "🔍 Verification Info (Hugging Face)\n",
      "──────────────────────────────────────────────────\u001B[0m\n",
      "\u001B[94m📝 Full Text:\u001B[0m\n",
      "'<|system|>\n",
      "You are an helpful assistant.\n",
      "<|user|>\n",
      "Explain quantum mechanics in detail please.\n",
      "<|assistant|>\n",
      "Quantum mechanics is a fundamental theory in physics that describes the physical properties of nature at the scale of atoms and subatomic particles, such as electrons, protons, and photons.'\n",
      "\u001B[94m🎯 Confidence Threshold:\u001B[0m 40.00%\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "| Step | Token           |  Probability | Status     |\n",
      "|------|-----------------|--------------|------------|\n",
      "|   55 | ,               |       56.61% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   56 |  such           |       89.17% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   57 |  as             |      100.00% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   58 |  electrons      |       98.04% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   59 | ,               |       95.45% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   60 |  protons        |       54.62% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   61 | ,               |       99.95% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   62 |  and            |       86.15% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   63 |  photons        |       97.68% | \u001B[92mAccepted  \u001B[0m |\n",
      "|   64 | .               |       98.09% | \u001B[92mAccepted  \u001B[0m |\n",
      "──────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'token': ',', 'prob': 0.5661389231681824, 'status': 'Accepted'},\n",
       " {'token': ' such', 'prob': 0.8916944265365601, 'status': 'Accepted'},\n",
       " {'token': ' as', 'prob': 0.9999815225601196, 'status': 'Accepted'},\n",
       " {'token': ' electrons', 'prob': 0.9804161190986633, 'status': 'Accepted'},\n",
       " {'token': ',', 'prob': 0.9544870853424072, 'status': 'Accepted'},\n",
       " {'token': ' protons', 'prob': 0.5462462306022644, 'status': 'Accepted'},\n",
       " {'token': ',', 'prob': 0.9995439648628235, 'status': 'Accepted'},\n",
       " {'token': ' and', 'prob': 0.861538290977478, 'status': 'Accepted'},\n",
       " {'token': ' photons', 'prob': 0.9768282175064087, 'status': 'Accepted'},\n",
       " {'token': '.', 'prob': 0.9809023141860962, 'status': 'Accepted'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:38.833487Z",
     "start_time": "2025-10-15T17:40:38.831534Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9ba44954f621c1ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:40:38.969654Z",
     "start_time": "2025-10-15T17:40:38.840325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = generate_draft_response(\n",
    "    model_path=config.quantized_path,\n",
    "    prompt=format_falcon_prompt(\n",
    "        tokenizer=tokenizer,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt\n",
    "    ),\n",
    "    ctx_size=config.n_ctx,\n",
    "    n_threads=config.n_threads,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    seed=config.seed,\n",
    "    verbose=config.verbose\n",
    ")"
   ],
   "id": "21a08671d4940dee",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_draft_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_draft_response\u001B[49m(\n\u001B[1;32m      2\u001B[0m     model_path\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mquantized_path,\n\u001B[1;32m      3\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mformat_falcon_prompt(\n\u001B[1;32m      4\u001B[0m         tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[1;32m      5\u001B[0m         system_prompt\u001B[38;5;241m=\u001B[39msystem_prompt,\n\u001B[1;32m      6\u001B[0m         user_prompt\u001B[38;5;241m=\u001B[39muser_prompt\n\u001B[1;32m      7\u001B[0m     ),\n\u001B[1;32m      8\u001B[0m     ctx_size\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_ctx,\n\u001B[1;32m      9\u001B[0m     n_threads\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mn_threads,\n\u001B[1;32m     10\u001B[0m     max_new_tokens\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_new_tokens,\n\u001B[1;32m     11\u001B[0m     seed\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mseed,\n\u001B[1;32m     12\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mverbose\n\u001B[1;32m     13\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generate_draft_response' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = speculative_decoding(\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    target_model=model,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    num_assistant_tokens=config.num_assistant_tokens,\n",
    "    confidence_threshold=config.assistant_confidence_threshold,\n",
    "    seed=config.seed,\n",
    "    verbose=True,\n",
    "    server_url=\"http://localhost:8080\"\n",
    ")"
   ],
   "id": "9f032cecf499723e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "asdf",
   "id": "3903ed1e828edfbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if config.debug:\n",
    "    print(format_falcon_prompt(\n",
    "        tokenizer=tokenizer,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        assistant_response=assistant_response\n",
    "    ))"
   ],
   "id": "fac02fdc6ed5536c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "generate_response(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    #num_assistant_tokens=config.num_assistant_tokens,\n",
    "    #assistant_confidence_threshold=config.assistant_confidence_threshold,\n",
    "    verbose=config.verbose\n",
    ")"
   ],
   "id": "d5aeb4438da2a81f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if config.debug:\n",
    "    generate_response(\n",
    "        tokenizer=tokenizer,\n",
    "        model=quantized_model,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        max_new_tokens=config.max_new_tokens,\n",
    "        #num_assistant_tokens=config.num_assistant_tokens,\n",
    "        #assistant_confidence_threshold=config.assistant_confidence_threshold,\n",
    "        verbose=config.verbose\n",
    "    )"
   ],
   "id": "7a9586e274619dad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if config.debug:\n",
    "    generate_response(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        assistant_model=quantized_model,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "        max_new_tokens=config.max_new_tokens,\n",
    "        num_assistant_tokens=config.num_assistant_tokens,\n",
    "        assistant_confidence_threshold=config.assistant_confidence_threshold,\n",
    "        verbose=config.verbose\n",
    "    )"
   ],
   "id": "a85fe85cfc7b44b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# C++",
   "id": "12226aae1e5f0541"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speculative Decoding",
   "id": "c13ba5f4d500af32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = generate_draft_response(\n",
    "    model_path=config.quantized_path,\n",
    "    prompt=format_falcon_prompt(\n",
    "        tokenizer=tokenizer,\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt\n",
    "    ),\n",
    "    ctx_size=config.n_ctx,\n",
    "    n_threads=config.n_threads,\n",
    "    max_new_tokens=10,\n",
    "    seed=config.seed,\n",
    "    verbose=False\n",
    ")\n",
    "res = verify_with_target(\n",
    "    context=sample,\n",
    "    tokenizer=tokenizer,\n",
    "    target_model=model,\n",
    "    num_assistant_tokens=10,\n",
    "    confidence_threshold=0.9,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "b0fc7d3d168602ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = speculative_decoding(\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=system_prompt,\n",
    "    user_prompt=user_prompt,\n",
    "    target_model=model,\n",
    "    draft_model=config.quantized_path,\n",
    "    ctx_size=config.n_ctx,\n",
    "    n_threads=config.n_threads,\n",
    "    max_new_tokens=config.max_new_tokens,\n",
    "    num_assistant_tokens=config.num_assistant_tokens,\n",
    "    confidence_threshold=config.assistant_confidence_threshold,\n",
    "    seed=config.seed,\n",
    "    verbose=True\n",
    ")"
   ],
   "id": "3dae326ca7b6934f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e96f19741eba5c09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
